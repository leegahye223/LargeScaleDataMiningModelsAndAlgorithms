{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime , timedelta\n",
    "from pytz import timezone\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26232\n",
      "214368\n",
      "1041319\n",
      "1531032\n",
      "1790056\n",
      "3138823\n"
     ]
    }
   ],
   "source": [
    "# aggregate\n",
    "files = ['tweets_#gopatriots.txt','tweets_#gohawks.txt','tweets_#sb49.txt',\n",
    "            'tweets_#patriots.txt','tweets_#nfl.txt','tweets_#superbowl.txt']\n",
    "rawdata = {'hours':list(),'tweets':list(),'retweet':list(),'followers':list(),\n",
    "        'maxfollowers':list(),'timeofday':list()}\n",
    "for filename in files:\n",
    "    with open(filename) as file:\n",
    "        for line in file:\n",
    "            data_line = json.loads(line)\n",
    "            cite_date = data_line['citation_date']\n",
    "            pst_tz = timezone('US/Pacific')\n",
    "            x = datetime.fromtimestamp(cite_date, pst_tz)\n",
    "            rawdata['hours'].append(x)\n",
    "            rawdata['tweets'].append(1)\n",
    "            rawdata['retweet'].append(data_line['metrics']['citations']['total'])  \n",
    "            rawdata['followers'].append(data_line['author']['followers'])\n",
    "            rawdata['maxfollowers'].append(data_line['author']['followers'])\n",
    "            rawdata['timeofday'].append(x.hour)\n",
    "            #data['usermention'].append(len(data_line['tweet']['entities']['user_mentions']))\n",
    "            #data['rankingscore'].append(data_line['metrics']['ranking_score'])\n",
    "    print(len(rawdata['hours']))\n",
    "rawdata = pd.DataFrame(rawdata, columns=['hours','tweets','retweet','followers','maxfollowers','timeofday'])\n",
    "#print(rawdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.200000e+02 7.590000e+02 2.472950e+05 4.181800e+04 0.000000e+00]\n",
      " [9.500000e+01 8.040000e+02 2.124180e+05 1.955800e+04 1.000000e+00]\n",
      " [1.160000e+02 6.560000e+02 1.659488e+06 1.362401e+06 2.000000e+00]\n",
      " ...\n",
      " [6.300000e+01 4.740000e+02 1.494713e+06 1.267836e+06 8.000000e+00]\n",
      " [5.300000e+01 1.100000e+02 6.238810e+05 1.590740e+05 9.000000e+00]\n",
      " [5.500000e+01 8.700000e+01 6.808590e+05 1.607590e+05 1.000000e+01]]\n"
     ]
    }
   ],
   "source": [
    "data_gp = rawdata.groupby(pd.Grouper(key='hours', freq='3600s'))\n",
    "\n",
    "data = {'tweets':list(),'retweet':list(),'followers':list(),'maxfollowers':list(),'timeofday':list()}\n",
    "for i,(j,group) in enumerate(data_gp):\n",
    "    data['tweets'].append(group.tweets.sum())\n",
    "    data['retweet'].append(group.retweet.sum())\n",
    "    data['followers'].append(group.followers.sum())\n",
    "    data['maxfollowers'].append(group.maxfollowers.max())\n",
    "    data['timeofday'].append(group.timeofday.max())\n",
    "data = pd.DataFrame(data, columns = ['tweets','retweet','followers','maxfollowers','timeofday'])\n",
    "#print(data)\n",
    "data = np.nan_to_num(data.values)\n",
    "print(data)\n",
    "\n",
    "time_line=data[:,4]\n",
    "num_dates=0\n",
    "#print(time_line)\n",
    "data1_end = ( 24-int(time_line[0]) ) + 17*24 + 8\n",
    "data1=data[0:data1_end, : ]\n",
    "#print(data1_end)\n",
    "\n",
    "data2_end = data1_end + 11 \n",
    "data2 = data[data1_end: data2_end, : ]\n",
    "#print(data2_end)\n",
    "\n",
    "data3 = data[data2_end : len(time_line), : ]\n",
    "#print(len(time_line))\n",
    "\n",
    "train_data = [data1,data2,data3]\n",
    "#print(train_data[0])\n",
    "#print(train_data[1])\n",
    "#print(train_data[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape(data):\n",
    "    data_end=data.shape[0]\n",
    "    data_reshape = []\n",
    "    data_x=data[0:5,: ]\n",
    "    data_x=np.reshape(data_x,25)\n",
    "    data_reshape = data_x\n",
    "    for i in range(1, data_end-5):\n",
    "        data_x=data[i:i+5,: ]\n",
    "        data_x=np.reshape(data_x,25)\n",
    "        data_reshape=np.vstack((data_reshape,data_x))\n",
    "    data_x=data_reshape\n",
    "    data_y=data[5:data_end,0]\n",
    "    #print(data_y[len(data_y)-1])\n",
    "    return data_x,data_y\n",
    "\n",
    "def reshape_sample8(data):\n",
    "    data_end=data.shape[0]\n",
    "    data_reshape = []\n",
    "    data_x=data[0:5,: ]\n",
    "    data_x=np.reshape(data_x,25)\n",
    "    data_reshape = data_x\n",
    "    for i in range(1, data_end-4):\n",
    "        data_x=data[i:i+4,: ]\n",
    "        data_x=np.reshape(data_x,25)\n",
    "        data_reshape=np.vstack((data_reshape,data_x))\n",
    "    data_x=data_reshape\n",
    "    data_y=data[4:data_end,0]\n",
    "    #print(data_y[len(data_y)-1])\n",
    "    return data_x,data_y\n",
    "\n",
    "def SamplePredict(period, samplename):\n",
    "    data_s = {'hours':list(),'tweets':list(),'retweet':list(),'followers':list(),\n",
    "              'maxfollowers':list(),'timeofday':list()}\n",
    "    with open('test_data/'+samplename+'.txt') as file:\n",
    "        for line in file:\n",
    "            data_line = json.loads(line)\n",
    "            cite_date = data_line['citation_date']\n",
    "            pst_tz = timezone('US/Pacific')\n",
    "            x = datetime.fromtimestamp(cite_date, pst_tz)\n",
    "            data_s['hours'].append(x)\n",
    "            data_s['tweets'].append(1)\n",
    "            data_s['retweet'].append(data_line['metrics']['citations']['total'])  \n",
    "            data_s['followers'].append(data_line['author']['followers'])\n",
    "            data_s['maxfollowers'].append(data_line['author']['followers'])\n",
    "            data_s['timeofday'].append(x.hour)\n",
    "            #data_s['usermention'].append(len(data_line['tweet']['entities']['user_mentions']))\n",
    "            #data_s['rankingscore'].append(data_line['metrics']['ranking_score'])\n",
    "    data_s = pd.DataFrame(data_s, columns = ['hours','tweets','retweet','followers','maxfollowers','timeofday'])\n",
    "    data_gp = data_s.groupby(pd.Grouper(key='hours', freq='3600s'))\n",
    "    data_s = {'tweets':list(),'retweet':list(),'followers':list(),'maxfollowers':list(),'timeofday':list()}\n",
    "    for i,(j,group) in enumerate(data_gp):\n",
    "        #data['hours'].append(i)\n",
    "        data_s['tweets'].append(group.tweets.sum())\n",
    "        data_s['retweet'].append(group.retweet.sum())\n",
    "        data_s['followers'].append(group.followers.sum())\n",
    "        data_s['maxfollowers'].append(group.maxfollowers.max())\n",
    "        data_s['timeofday'].append(group.timeofday.max())\n",
    "    data_s = pd.DataFrame(data_s, columns = ['tweets','retweet','followers','maxfollowers','timeofday'])\n",
    "    #print(data_s)\n",
    "    data_s = data_s.values[0:6,:]\n",
    "    if samplename=='sample8_period1':\n",
    "        data_s = data_s[0:5,:]\n",
    "    #print(data_s)\n",
    "    train_x,train_y = reshape(train_data[period-1])\n",
    "    test_x,test_y = reshape(data_s)\n",
    "    if samplename=='sample8_period1':\n",
    "        test_x,test_y = reshape_sample8(data_s)\n",
    "    rf = RandomForestRegressor(n_estimators=20, max_features=4, max_depth=4, \n",
    "                               bootstrap=True, oob_score=True, n_jobs=-1, random_state=42)\n",
    "    rf.fit(train_x, train_y)\n",
    "    predict_y = rf.predict(test_x.reshape(1,-1))\n",
    "    score = rf.score(test_x.reshape(1,-1),test_y)\n",
    "    print(samplename+\": \")\n",
    "    print('predict value =',predict_y[0])\n",
    "    print('true value =',test_y[0])\n",
    "    #print('score =',score)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Period 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample1_period1: \n",
      "predict value = 507.8646761617787\n",
      "true value = 177.0\n",
      "\n",
      "sample4_period1: \n",
      "predict value = 560.6267008397111\n",
      "true value = 201.0\n",
      "\n",
      "sample5_period1: \n",
      "predict value = 484.0790834812191\n",
      "true value = 215.0\n",
      "\n",
      "sample8_period1: \n",
      "predict value = 345.4584684684563\n",
      "true value = 11.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SamplePredict(1, 'sample1_period1')\n",
    "SamplePredict(1, 'sample4_period1')\n",
    "SamplePredict(1, 'sample5_period1')\n",
    "SamplePredict(1, 'sample8_period1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Period 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample2_period2: \n",
      "predict value = 249004.2\n",
      "true value = 83440.0\n",
      "\n",
      "sample6_period2: \n",
      "predict value = 175661.4\n",
      "true value = 37199.0\n",
      "\n",
      "sample9_period2: \n",
      "predict value = 237987.2\n",
      "true value = 2788.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SamplePredict(2, 'sample2_period2')\n",
    "SamplePredict(2, 'sample6_period2')\n",
    "SamplePredict(2, 'sample9_period2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Period 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample3_period3: \n",
      "predict value = 1296.6450157475554\n",
      "true value = 523.0\n",
      "\n",
      "sample7_period3: \n",
      "predict value = 121.20988042599456\n",
      "true value = 120.0\n",
      "\n",
      "sample10_period3: \n",
      "predict value = 97.14126556112969\n",
      "true value = 61.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SamplePredict(3, 'sample3_period3')\n",
    "SamplePredict(3, 'sample7_period3')\n",
    "SamplePredict(3, 'sample10_period3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
